"""Prometheus metrics definitions and instrumentation utilities.

This module defines the metrics used across the backend and the quality job.
FastAPI applications can use the `instrument_app` function to automatically
collect request metrics, and the quality job can import and update the
metrics directly when checks are executed. The metrics endpoint itself is
exposed via `prometheus_client.make_asgi_app` in `main.py`.
"""

import time
from typing import Callable

from fastapi import Request, Response
from prometheus_client import Counter, Histogram


# HTTP request metrics
HTTP_REQUEST_COUNT = Counter(
    "http_requests_total",
    "Total number of HTTP requests",
    ["method", "endpoint", "status_code"],
)

HTTP_REQUEST_LATENCY = Histogram(
    "http_request_duration_seconds",
    "Latency of HTTP requests in seconds",
    ["method", "endpoint"],
)

HTTP_REQUEST_ERRORS = Counter(
    "http_request_errors_total",
    "Total number of erroneous HTTP responses",
    ["method", "endpoint", "status_code"],
)

# Quality job metrics
INCIDENTS_TOTAL = Counter(
    "incidents_total",
    "Total number of incidents generated by the quality job",
    ["dataset", "rule_type", "severity"],
)

CHECKS_RUN_TOTAL = Counter(
    "checks_run_total",
    "Total number of checks executed",
    ["dataset", "rule_type"],
)

CHECK_DURATION_SECONDS = Histogram(
    "check_duration_seconds",
    "Duration of quality checks in seconds",
    ["dataset", "rule_type"],
)


async def metrics_middleware(request: Request, call_next: Callable[[Request], Response]) -> Response:
    """Middleware for recording HTTP request metrics.

    Records the total count, latency and errors for each request. The
    endpoint label is derived from the route path template when available.
    """

    method = request.method
    # Use the route name if available, otherwise the raw path
    endpoint = request.scope.get("path") or "unknown"
    start_time = time.perf_counter()
    try:
        response = await call_next(request)
    except Exception:
        status_code = 500
        HTTP_REQUEST_COUNT.labels(method=method, endpoint=endpoint, status_code=status_code).inc()
        HTTP_REQUEST_ERRORS.labels(method=method, endpoint=endpoint, status_code=status_code).inc()
        raise
    else:
        status_code = response.status_code
        HTTP_REQUEST_COUNT.labels(method=method, endpoint=endpoint, status_code=status_code).inc()
        if status_code >= 400:
            HTTP_REQUEST_ERRORS.labels(method=method, endpoint=endpoint, status_code=status_code).inc()
        return response
    finally:
        latency = time.perf_counter() - start_time
        HTTP_REQUEST_LATENCY.labels(method=method, endpoint=endpoint).observe(latency)


def record_incident(dataset: str, rule_type: str, severity: str) -> None:
    """Increment the incident counter for the given labels."""

    INCIDENTS_TOTAL.labels(dataset=dataset, rule_type=rule_type, severity=severity).inc()


def record_check(dataset: str, rule_type: str, duration: float) -> None:
    """Record metrics for a single check execution."""

    CHECKS_RUN_TOTAL.labels(dataset=dataset, rule_type=rule_type).inc()
    CHECK_DURATION_SECONDS.labels(dataset=dataset, rule_type=rule_type).observe(duration)